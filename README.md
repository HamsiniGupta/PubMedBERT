# PubMedBERT: Retrieval-Augmented Generation for Biomedical Question Answering

Large Language Models struggle with biomedical Q/A due to hallucinations and outdated knowledge. Our research addresses these limitations by developing PubMedBERT, a domain-specific retriever model trained using Simple Contrastive Sentence Embeddings (SimCSE) on the PubMedQA labeled dataset.
Our implementation of the RAG framework includes testing the PubMedBERT model with Llama3-OpenBioLLM-8B (achieving 64% accuracy) and Llama-3.1-8B (achieving 61% accuracy).







